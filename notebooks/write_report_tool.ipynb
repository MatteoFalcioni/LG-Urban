{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326f9c9c",
   "metadata": {},
   "source": [
    "# Implementing the `write_report()` tool and testing it out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2df0d",
   "metadata": {},
   "source": [
    "## Brainstorming\n",
    "\n",
    "\n",
    "\n",
    "We want the model to be able to produce a report of the analysis performed. \n",
    "\n",
    "What it should do:\n",
    "\n",
    "1. *Get the full chat history in order to see al relevant analysis performed*\n",
    "    \n",
    "    **challenges:** \n",
    "\n",
    "    - If chat gets summarized, previous analysis are blurred out. We need detailed history, but at the same time we cannot input more than a certain number of tokens to the model that produces the analysis. \n",
    "    \n",
    "    **solutions:**\n",
    "\n",
    "    - we need to keep the full chat state somewhere when we summarize. Maybe store it in state. Could be a long `analysis` str, or could be a virtual file in the virtual file system. Then the `write_report()` tool could split the full history in sections in order not to exceed context length.     \n",
    "\n",
    "2. *Collect all sources used - meaning, the list of all datasets analized*\n",
    "    \n",
    "    **challenges:**\n",
    "\n",
    "    - We have to keep track of all used datasets.\n",
    "    \n",
    "    **solutions:**\n",
    "    \n",
    "    - Just add a state var `sources`; it gets filled every time we **select** a dataset with the `select_dataset` tool. The model that writes the report can then cite the source throughout the report, understanding when it was used from chat history.\n",
    "\n",
    "3. *Produce an extensive report (.md format probably)*\n",
    "\n",
    "----\n",
    "\n",
    "> **? Should the report include python code ?**\n",
    ">\n",
    "> It could be useful to include in the report - or somewhere else - all python code written during the analysis. \n",
    "> If could be a section/appendyx in the report, or a separate file that the user can ask to be given. \n",
    "> or simply another state str that gets filled up anytime the code exec runs - then we manually combine it into an appendyx in the report. i Just don't want it to be like 3000 lines at the end of the report. maybe they should be separate files. \n",
    "\n",
    "> *DB Related:* This extra stuff needs to remain visible to the user when he goes back to previous chats - add those in the db \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d2d9",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674ed22",
   "metadata": {},
   "source": [
    "Let's replicate the graph below, but simulate the analysis in some way...\n",
    "\n",
    "We can \n",
    "\n",
    "1. create a new state with the new state vars we need\n",
    "2. give the model a simpler repl tool that can still generate python code and get stdout and stderr - or make it fake\n",
    "3. give the model a fake select ds tool that adds the sources to state var\n",
    "4. create the real write_report() tool (and a nice prompt) for the model to use all the rest. \n",
    "5. make it write to file so we can read it.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788e591",
   "metadata": {},
   "source": [
    "### 1. State Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32becc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from typing import Annotated\n",
    "\n",
    "def list_add(left: list[str] | None = None, right: str | None = None) -> list[str]:\n",
    "    \"\"\"\n",
    "    Reducer to add a new item to a list. Used for sources and code.\n",
    "    \"\"\"\n",
    "    if left is None:\n",
    "        left = []\n",
    "    if right is None:\n",
    "        right = []\n",
    "    \n",
    "    return left + right\n",
    "\n",
    "class MyState(AgentState):\n",
    "    # here we would have also summary and token count\n",
    "    sources : Annotated[list[dict[str, str]], list_add] # key is the dataset id, value is the dataset description\n",
    "    code: Annotated[list[dict[str, str]], list_add]  # list of dicts, each dicts is input and output of a code block (out can be stdout or stderr)\n",
    "    report: Annotated[list[dict[str, str]], list_add]  # key is the title, value is the content - but there could be more than one report so list of dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9177e",
   "metadata": {},
   "source": [
    "Will these reducers work well with left + right if they are dicts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989407e",
   "metadata": {},
   "source": [
    "### 2. & 3. Fake tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "@tool\n",
    "def code_exec(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ")->Command: \n",
    "    \"\"\"Use this to execute python code.\"\"\"\n",
    "\n",
    "    result = \"\"\"# code executed succesfully\"\"\"  # this would be stdout\n",
    "    code_dict = {\"input\": code, \"output\": result}\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content = result, tool_call_id = tool_call_id)],\n",
    "            \"code\": [code_dict], # wrap in list for reducer\n",
    "        }\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def list_datasets(\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ")->Command:\n",
    "    \"\"\"\n",
    "    List all available datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    fake_ds = [\"dataset1\", \"dataset2\", \"dataset3\"]\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content = f\"Here are the available datasets: {fake_ds}\", tool_call_id = tool_call_id)],\n",
    "        }\n",
    "    )\n",
    "\n",
    "@tool \n",
    "def select_dataset(\n",
    "    dataset_id: str,\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ")->Command:\n",
    "    \"\"\"\n",
    "    Select a dataset from the list of available datasets. Adds it to the list of sources.\n",
    "    \"\"\"\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content = f\"Selected and loaded dataset {dataset_id}\", tool_call_id = tool_call_id)],\n",
    "            \"sources\" : [dataset_id]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe0aaf",
   "metadata": {},
   "source": [
    "### 4. & 5. Write report tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import InjectedState\n",
    "\n",
    "def write_report(\n",
    "    report_title: Annotated[str, \"The title of the report\"],\n",
    "    report_content: Annotated[str, \"The content of the report\"],\n",
    "    state: Annotated[InjectedState, MyState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ")->Command:\n",
    "    \"\"\"\n",
    "    Write a report of the analysis performed.\n",
    "    \"\"\"\n",
    "\n",
    "    report_dict = {report_title: report_content}\n",
    "\n",
    "    # also write to file in dev\n",
    "    with open(\"report.md\", \"a\") as f:\n",
    "        f.write(f\"# {report_title}\\n{report_content}\\n\\n\")\n",
    "\n",
    "    return Command(\n",
    "        update = {\n",
    "            \"messages\" : [ToolMessage(content = \"Report written\", tool_call_id = tool_call_id)],\n",
    "            \"report\" : [report_dict]\n",
    "        }\n",
    "    )\n",
    "\n",
    "# probably should make a modify_report() tool that can be used to add to modify an existing report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230960bb",
   "metadata": {},
   "source": [
    "How should i make it add sources? first make the report than another pass for sources? A `read_sources` tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389100a2",
   "metadata": {},
   "source": [
    "### 6. Create a well rounded prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee915a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_prompt = \"\"\"\n",
    "You are an AI assitant that works together with a data analyst colleague.\n",
    "\n",
    "After the data analyst performs an analysis, you will be asked to write a report of the analysis performed.\n",
    "\n",
    "You will be given a list of sources used in the analysis.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
